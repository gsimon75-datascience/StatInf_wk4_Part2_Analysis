---
title: |
 | Statistical Inference
 | Analysis of the ToothGrowth data
author: "Gabor Simon"
output: 
  pdf_document:
          toc: true
---

## Overview

We are doing an Inferential Data Analysis on the ToothGrowth dataset of the
R library 'datasets': "The Effect of Vitamin C on Tooth Growth in Guinea Pigs".

```{r setup_environment, message = FALSE}
library(datasets)
library(dplyr)
library(ggplot2)
# We want the same data on each run
set.seed(1507471380)
```

The built-in help of the dataset says:

>     ...
>     Description:
>          The response is the length of odontoblasts (cells responsible for
>          tooth growth) in 60 guinea pigs.  Each animal received one of
>          three dose levels of vitamin C (0.5, 1, and 2 mg/day) by one of
>          two delivery supplements, (orange juice or ascorbic acid (a form of
>          vitamin C and coded as 'VC').
>     
>     Format:
>          A data frame with 60 observations on 3 variables.
>            [,1]  len   numeric  Tooth length                
>            [,2]  supp  factor   Supplement type (VC or OJ). 
>            [,3]  dose  numeric  Dose in milligrams/day      
>     ...

\pagebreak

## Exploratory Data Analysis

To get some first-glance ideas, let's take a look at the data.

### The tooth length distributions by dose and supplement type
```{r eda_1, message = FALSE}
ggplot(ToothGrowth, aes(factor(dose), len)) + facet_grid(~supp) + geom_boxplot()
```
\pagebreak

### The individual sample distributions for each (dose,supp) pair
```{r eda_2, message = FALSE}
ggplot(ToothGrowth, aes(len)) + facet_grid(dose~supp) + geom_histogram(bins=20)
```

### Our approximate observations
1. For both supplements, higher doses result longer teeth
2. For 0.5 and 1.0 mg/day, the 'OJ' supplement results longer teeth than the 'VC'
3. For 2.0 mg/day, the difference is insignificant
4. Due to the low number of samples, the distributions are not recognisable
   as normals, but they aren't too sloped either.

\pagebreak

## Basic Inferential Data Analysis

So our null hypotheses will be that all dosages and supplements result the same
tooth growth, and the alternative hypotheses will be that one (dose,supp) pair
results more than the other.

This will give us quite a number of hypotheses, so the pitfalls of multiple
testing shall be considered as well.

As we cannot assume the distributions to be normal, we resort to t-tests.

The following wrapper functions make such tests easier:

```{r test_wrapper, message = FALSE}

# We collect the alternative hypotheses here for p-adjustment
hypotheses <- vector()

# Test whether the tooth length in case of {dose,supp}A is greater than for {dose,supp}0
# and collect the p-values in the @hypotheses vector, because we'll have to do p-adjustment
# on them before printing
test_and_collect <- function(dose0, supp0, doseA, suppA) {
	description <- paste("(", doseA, ",", suppA, ")",
			     " more effective than ",
			     "(", dose0, ",", supp0, ")",
			     sep = "")

	# H0: len(dose0, supp0) = len(doseA, suppA)
	# HA: len(dose0, supp0) < len(doseA, suppA)
	# If the p-value is low enough, then H0 can be rejected and HA may be assumed true
	# If the p-value is too high, then we failed to reject H0
	p <- t.test(ToothGrowth$len[ToothGrowth$dose == doseA & ToothGrowth$supp == suppA],
		    ToothGrowth$len[ToothGrowth$dose == dose0 & ToothGrowth$supp == supp0],
		    alternative = "greater")$p.value

	hypotheses[description] <<- p
}

# Check whether OJ > VC with @dose, or the opposite, or neither
test_dose <- function(dose) {
	hypotheses <<- vector()
	test_and_collect(dose, "VC", dose, "OJ")
	test_and_collect(dose, "OJ", dose, "VC")
	hypotheses <<- p.adjust(hypotheses, method = "BH")
	for (h in names(hypotheses))
		print(paste("HA={", h, "}:", hypotheses[h]))
}

# Check whether 2.0 > 1.0 > 0.5 for @supp, or the opposite, or neither
test_supplement <- function(supp) {
	hypotheses <<- vector()
	test_and_collect(0.5, supp, 1.0, supp)
	test_and_collect(1.0, supp, 0.5, supp)
	test_and_collect(1.0, supp, 2.0, supp)
	test_and_collect(2.0, supp, 1.0, supp)
	hypotheses <<- p.adjust(hypotheses, method = "BH")
	for (h in names(hypotheses))
		print(paste("HA={", h, "}:", hypotheses[h]))
}
```

### The p-values for our hypotheses

Remember, for all the following tests the null hypothesis H0 is that
both (dose,supp) pairs are equally efficient, and if a **p-value is low enough**, then
can we reject this H0 and **accept HA as true**.

### Testing hypotheses about doses

For each dose we have two alternative hypotheses ("VC > OJ" and "OJ > VC"),
so a Benjamini-Hochberg is not definitely needed, but we will need it anyway later,
so we are performing it by default.

```{r test_dose_hypotheses, message = FALSE}
test_dose(0.5)
test_dose(1.0)
test_dose(2.0)
```

### Testing hypotheses about supplements

For the supplement types we have 4 hypotheses (in fact, we could
check for all 6 permutations of ordering the 3 dosages, making it 12 one-sided tests),
so a Bonferroni correction would cost us a whole magnitude of $\alpha$,
so here a B-H correction is a must.

```{r test_supp_hypotheses, message = FALSE}
test_supplement("VC")
test_supplement("OJ")
```


## Conclusions
1. For doses 0.5 and 1.0 mg/day, "OJ" is more effective than "VC" ($\alpha < 0.0064$)
2. For 2.0 mg/day there is no significant difference between the supplements' effectiveness.
3. For both supplement types a higher dose is more effective ($\alpha < 0.04$)

During the process we relied on a set of assumptions:

* The effects of the supplement and of the dosage are independent
* The effects of the dosage are monotone (either increasing or decreasing)
* The individual distributions of the (dose,supp) pairs are valid for applying t-tests
